"""
Advanced RAG ì²´ì¸: ê²€ìƒ‰ + LLM + ì™¸ë¶€ API
"""

from typing import List, Dict, Any, Optional, AsyncIterator
import os
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from app.vectorstore import get_vectorstore
from app.utils import logger
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class RAGChain:
    """RAG íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """RAG ì²´ì¸ ì´ˆê¸°í™”"""
        # OpenAI LLM ì´ˆê¸°í™”
        # ChatOpenAIëŠ” í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ìë™ìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # GPT-4o-mini ëª¨ë¸ ì‚¬ìš©
            temperature=0.7,
            max_tokens=500  # ì‘ë‹µ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì†ë„ ê°œì„ 
        )
        
        # ë²¡í„° ì €ì¥ì†Œ ê°€ì ¸ì˜¤ê¸°
        self.vectorstore = get_vectorstore()
        
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
        self.memories: Dict[str, List[BaseMessage]] = {}
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê°„ì†Œí™”ëœ í˜•ì‹)
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ë„ˆëŠ” ì „ì£¼ ì§€ì—­ ìŒì‹ì ê³¼ ìŒì‹ ì¶”ì²œë§Œ ì œê³µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.

ğŸš« ì ˆëŒ€ ê·œì¹™:
1. ì œê³µëœ ìŒì‹ì  ë°ì´í„°(RAG/ë²¡í„° DB)ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŒì‹ì ì´ë‚˜ ë©”ë‰´ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
3. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì†”ì§í•˜ê²Œ ë¶€ì¡±í•˜ë‹¤ê³  ë§í•˜ì„¸ìš”.
4. ë‹µë³€ì€ ì§§ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
5. ê²€ìƒ‰ëœ ë©”ë‰´ ì¤‘ 2-3ê°œë¥¼ ì¶”ì²œí•˜ì„¸ìš”.
6. ê° ë©”ë‰´ì˜ ìŒì‹ì ëª…, ë©”ë‰´ëª…, ê°€ê²©, ì¹¼ë¡œë¦¬, ì£¼ì†Œë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.
7. ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­(ê°€ê²©, ì¹¼ë¡œë¦¬, ì¹´í…Œê³ ë¦¬)ì„ ë°˜ì˜í•˜ì„¸ìš”.

ë©”ë‰´ ëª©ë¡:
{context}"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{question}")
        ])
    
    def _get_memory(self, conversation_id: Optional[str] = None) -> List[BaseMessage]:
        """ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if conversation_id is None:
            conversation_id = "default"
        
        if conversation_id not in self.memories:
            self.memories[conversation_id] = []
        
        return self.memories[conversation_id]
    
    def _extract_preferences(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ"""
        preferences = {
            "category": None,
            "price_range": None,
            "max_price": None,
            "max_calories": None,
            "keywords": []
        }
        
        question_lower = question.lower()
        
        # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        categories = ["í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ë¶„ì‹", "ì¹˜í‚¨", "í”¼ì", "ì¹´í˜"]
        for cat in categories:
            if cat in question:
                preferences["category"] = cat
                break
        
        # ê°€ê²© ê´€ë ¨ í‚¤ì›Œë“œ
        price_keywords = {
            "ì €ë ´": "low",
            "ì‹¼": "low",
            "ì €ê°€": "low",
            "ë¹„ì‹¼": "high",
            "ê³ ê¸‰": "high",
            "í”„ë¦¬ë¯¸ì—„": "high",
            "ì ë‹¹í•œ": "medium"
        }
        for keyword, range_type in price_keywords.items():
            if keyword in question_lower:
                preferences["price_range"] = range_type
                break
        
        # ê°€ê²© ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "1ë§Œì› ì´í•˜", "15000ì›")
        import re
        price_matches = re.findall(r'(\d+)\s*ë§Œ?\s*ì›', question)
        if price_matches:
            try:
                price = int(price_matches[0])
                if "ë§Œ" in question or price > 1000:
                    price = price * 10000 if price < 1000 else price
                preferences["max_price"] = price
            except ValueError:
                pass
        
        # ì¹¼ë¡œë¦¬ ê´€ë ¨
        if "ì¹¼ë¡œë¦¬" in question or "ë‹¤ì´ì–´íŠ¸" in question_lower or "ì €ì¹¼ë¡œë¦¬" in question_lower:
            calorie_matches = re.findall(r'(\d+)\s*ì¹¼ë¡œë¦¬', question)
            if calorie_matches:
                try:
                    preferences["max_calories"] = int(calorie_matches[0])
                except ValueError:
                    pass
        
        return preferences
    
    def _format_context(self, search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê°„ì†Œí™”ëœ í˜•ì‹)"""
        if not search_results:
            return "ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë‹¨ì¶•
        context_parts = []
        for i, result in enumerate(search_results[:5], 1):
            metadata = result.get("metadata", {})
            
            # ê°„ê²°í•œ í•œ ì¤„ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
            restaurant_name = metadata.get("restaurant_name", "")
            menu_name = metadata.get("menu_name", "")
            price = metadata.get("price", "")
            calories = metadata.get("calories", "")
            address = metadata.get("address", "")
            category = metadata.get("category", "")
            
            # í•œ ì¤„ë¡œ ì••ì¶•: "1. ìŒì‹ì ëª… - ë©”ë‰´ëª… (ê°€ê²©ì›, ì¹¼ë¡œë¦¬kcal) [ì£¼ì†Œ]"
            menu_info = f"{i}. {restaurant_name} - {menu_name}"
            if price:
                menu_info += f" ({price}ì›"
                if calories:
                    menu_info += f", {calories}kcal"
                menu_info += ")"
            if address:
                menu_info += f" [{address}]"
            if category:
                menu_info += f" ({category})"
            
            context_parts.append(menu_info)
        
        return "\n".join(context_parts)
    
    def invoke(
        self,
        question: str,
        conversation_id: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """
        ì§ˆë¬¸ì„ ë°›ì•„ RAGë¥¼ í†µí•´ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            conversation_id: ëŒ€í™” ID (ì„ íƒì‚¬í•­)
            history: ëŒ€í™” ê¸°ë¡ (ì„ íƒì‚¬í•­)
        
        Returns:
            ë‹µë³€ê³¼ ì†ŒìŠ¤ ì •ë³´ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            step_times = {}
            total_start = time.time()
            
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ
            start = time.time()
            preferences = self._extract_preferences(question)
            step_times['preference_extraction'] = time.time() - start
            logger.info(f"ì¶”ì¶œëœ ì„ í˜¸ë„: {preferences}")
            
            # 2. ë²¡í„° ê²€ìƒ‰ (í•„í„°ë§ ì ìš©)
            start = time.time()
            logger.info(f"ì§ˆë¬¸ ê²€ìƒ‰ ì¤‘: {question}")
            if preferences.get("category") or preferences.get("max_price") or preferences.get("max_calories"):
                # í•„í„°ë§ ê²€ìƒ‰ ì‚¬ìš©
                search_results = self.vectorstore.search_with_filters(
                    query=question,
                    category=preferences.get("category"),
                    max_price=preferences.get("max_price"),
                    max_calories=preferences.get("max_calories"),
                    k=5  # 8 â†’ 5ë¡œ ì¤„ì—¬ì„œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë‹¨ì¶•
                )
            else:
                # ì¼ë°˜ ê²€ìƒ‰
                search_results = self.vectorstore.similarity_search(question, k=5)  # 8 â†’ 5ë¡œ ì¤„ì„
            step_times['vector_search'] = time.time() - start
            
            # 3. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
            start = time.time()
            context = self._format_context(search_results)
            step_times['context_formatting'] = time.time() - start
            
            # 4. ëŒ€í™” ê¸°ë¡ ì¤€ë¹„
            start = time.time()
            memory = self._get_memory(conversation_id)
            
            # historyê°€ ì œê³µë˜ë©´ ë©”ëª¨ë¦¬ì— ì¶”ê°€
            if history:
                for msg in history:
                    if msg.get("role") == "user":
                        memory.append(HumanMessage(content=msg.get("content", "")))
                    elif msg.get("role") == "assistant":
                        memory.append(AIMessage(content=msg.get("content", "")))
            step_times['memory_preparation'] = time.time() - start
            
            # 5. í”„ë¡¬í”„íŠ¸ ìƒì„±
            start = time.time()
            chat_history = memory[-6:] if len(memory) > 6 else memory  # ìµœê·¼ 6ê°œë§Œ
            
            prompt = self.prompt_template.format_messages(
                context=context,
                history="\n".join([f"{'ì‚¬ìš©ì' if isinstance(m, HumanMessage) else 'ì±—ë´‡'}: {m.content}" 
                                  for m in chat_history]),
                question=question,
                chat_history=chat_history
            )
            step_times['prompt_creation'] = time.time() - start
            
            # 6. LLM í˜¸ì¶œ
            start = time.time()
            logger.info("LLM í˜¸ì¶œ ì¤‘...")
            response = self.llm.invoke(prompt)
            answer = response.content if hasattr(response, 'content') else str(response)
            step_times['llm_call'] = time.time() - start
            
            # 7. ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            start = time.time()
            memory.append(HumanMessage(content=question))
            memory.append(AIMessage(content=answer))
            
            # 8. ì†ŒìŠ¤ ì •ë³´ ë° ì¶”ì²œ ë©”ë‰´ ì¤€ë¹„
            sources = []
            recommended_menus = []
            
            for r in search_results[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶”ì²œ
                metadata = r.get("metadata", {})
                source_info = {
                    "content": r.get("content", ""),
                    "metadata": metadata,
                    "score": r.get("score")
                }
                sources.append(source_info)
                
                # ì¶”ì²œ ë©”ë‰´ ì •ë³´ ì¶”ì¶œ
                if metadata.get("menu_name") and metadata.get("restaurant_name"):
                    recommended_menus.append({
                        "restaurant_name": metadata.get("restaurant_name", ""),
                        "menu_name": metadata.get("menu_name", ""),
                        "price": str(metadata.get("price", "")),
                        "calories": str(metadata.get("calories", "")),
                        "address": metadata.get("address", ""),
                        "category": metadata.get("category", ""),
                        "score": r.get("score")
                    })
            step_times['result_preparation'] = time.time() - start
            
            # ì´ ì‹œê°„ ê³„ì‚°
            total_time = time.time() - total_start
            step_times['total'] = total_time
            
            # ë‹¨ê³„ë³„ ì‹œê°„ ë¡œê·¸ ì¶œë ¥
            logger.info("=" * 60)
            logger.info("ë‹¨ê³„ë³„ ì‘ë‹µ ì‹œê°„ ë¶„ì„")
            logger.info("=" * 60)
            for step, elapsed in step_times.items():
                percentage = (elapsed / total_time * 100) if total_time > 0 else 0
                logger.info(f"  {step:25s}: {elapsed:6.2f}ì´ˆ ({percentage:5.1f}%)")
            logger.info("=" * 60)
            
            return {
                "response": answer,
                "sources": sources,
                "recommended_menus": recommended_menus
            }
            
        except Exception as e:
            logger.error(f"RAG ì²´ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
            return {
                "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": []
            }
    
    async def stream(
        self,
        question: str,
        conversation_id: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None
    ) -> AsyncIterator[str]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            conversation_id: ëŒ€í™” ID (ì„ íƒì‚¬í•­)
            history: ëŒ€í™” ê¸°ë¡ (ì„ íƒì‚¬í•­)
        
        Yields:
            ë‹µë³€ì˜ ì²­í¬ ë¬¸ìì—´
        """
        try:
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ
            preferences = self._extract_preferences(question)
            
            # 2. ë²¡í„° ê²€ìƒ‰ (í•„í„°ë§ ì ìš©)
            if preferences.get("category") or preferences.get("max_price") or preferences.get("max_calories"):
                search_results = self.vectorstore.search_with_filters(
                    query=question,
                    category=preferences.get("category"),
                    max_price=preferences.get("max_price"),
                    max_calories=preferences.get("max_calories"),
                    k=5  # 8 â†’ 5ë¡œ ì¤„ì—¬ì„œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë‹¨ì¶•
                )
            else:
                search_results = self.vectorstore.similarity_search(question, k=5)  # 8 â†’ 5ë¡œ ì¤„ì„
            
            context = self._format_context(search_results)
            
            # 2. ëŒ€í™” ê¸°ë¡ ì¤€ë¹„
            memory = self._get_memory(conversation_id)
            if history:
                for msg in history:
                    if msg.get("role") == "user":
                        memory.append(HumanMessage(content=msg.get("content", "")))
                    elif msg.get("role") == "assistant":
                        memory.append(AIMessage(content=msg.get("content", "")))
            
            chat_history = memory[-6:] if len(memory) > 6 else memory
            
            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.prompt_template.format_messages(
                context=context,
                history="\n".join([f"{'ì‚¬ìš©ì' if isinstance(m, HumanMessage) else 'ì±—ë´‡'}: {m.content}" 
                                  for m in chat_history]),
                question=question,
                chat_history=chat_history
            )
            
            # 4. ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
            full_response = ""
            async for chunk in self.llm.astream(prompt):
                # chunkê°€ AIMessageChunkì¸ ê²½ìš° ì²˜ë¦¬
                if hasattr(chunk, 'content'):
                    content = chunk.content
                    # contentê°€ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜
                    if not isinstance(content, str):
                        content = str(content) if content is not None else ""
                else:
                    content = str(chunk) if chunk is not None else ""
                
                # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ yield
                if content and content.strip():
                    full_response += content
                    yield content
                # ë¹ˆ ë¬¸ìì—´ì´ì–´ë„ Noneì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬ (ì˜ˆ: ê³µë°± ë¬¸ì)
                elif content is not None and len(content) > 0:
                    full_response += content
                    yield content
            
            # 5. ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            memory.append(HumanMessage(content=question))
            memory.append(AIMessage(content=full_response))
            
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
            yield f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_rag_chain_instance: Optional[RAGChain] = None


def get_rag_chain() -> RAGChain:
    """RAG ì²´ì¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _rag_chain_instance
    if _rag_chain_instance is None:
        _rag_chain_instance = RAGChain()
    return _rag_chain_instance
